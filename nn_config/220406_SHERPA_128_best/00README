History:
	- 2022-Apr-06: Written, FIS

Description:
	- This 00README file describes how the "best" SHERPA case 
	  for the 128-nodes for each output. What changes between
	  outputs is, therefore, only the num. of hidden layers.

Procedure:
	The complexity of the NN (num. of trainable parameters) are primarily
	determined by the num. of nodes, and secondary by the num. of hidden
	layers. The procedure described below is motivated by the fact that 
	NNs are parameters "hungry", i.e., in general the more trainable 
	parameters the smaller validation loss.  
	
	- SHERPA trials and loss (objective). For each output, it was chosen 
	  the "best" case based on 128-nodes, i.e., shallowest model (num. of 
	  hidden layers) that achieve the lowest loss (objective) using two 
	  significant figures.		    
	  