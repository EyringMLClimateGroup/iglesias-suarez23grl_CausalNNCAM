{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SingleNNs Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script runs a number of diagnostics that evaluate the performance of both, SingleNNs & CausalSingleNNs offline (i.e., using test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from utils.setup import SetupDiagnostics\n",
    "\n",
    "# argv  = sys.argv[1:]\n",
    "argv  = [\"-c\", \"./nn_config/cfg_SingleNNs_Diagnostics.yml\"]\n",
    "\n",
    "setup = SetupDiagnostics(argv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can check both, attributes and methods in **setup** by, for example:\\\n",
    "**dir(setup)\\\n",
    "setup.__dict__** # setup.__dict__.keys() & setup.__dict__.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def get_path(setup, model_type, *, pc_alpha=None, threshold=None):\n",
    "    \"\"\" Generate a path based on this model metadata \"\"\"\n",
    "    path = Path(setup.nn_output_path, model_type)\n",
    "    if model_type == \"CausalSingleNN\":\n",
    "        path = path / Path(\n",
    "            \"a{pc_alpha}-t{threshold}/\".format(\n",
    "                pc_alpha=pc_alpha, threshold=threshold\n",
    "            )\n",
    "        )\n",
    "    str_hl = str(setup.hidden_layers).replace(\", \", \"_\")\n",
    "    str_hl = str_hl.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    path = path / Path(\n",
    "        \"hl_{hidden_layers}-act_{activation}-e_{epochs}/\".format(\n",
    "            hidden_layers=str_hl,\n",
    "            activation=setup.activation,\n",
    "            epochs=setup.epochs,\n",
    "        )\n",
    "    )\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.variable import Variable_Lev_Metadata\n",
    "def get_filename(setup, output):\n",
    "    \"\"\" Generate a filename to save the model \"\"\"\n",
    "    i_var   = setup.output_order.index(output.var)\n",
    "    i_level = output.level_idx\n",
    "    if i_level is None:\n",
    "        i_level = 0\n",
    "    return f\"{i_var}_{i_level}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_plot_folder(setup, model_type, output, *, pc_alpha=None, threshold=None):\n",
    "    folder = get_path(setup, model_type, pc_alpha=pc_alpha, threshold=threshold)\n",
    "    path   = Path(folder, 'diagnostics')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "def get_model(setup, output, model_type, *, pc_alpha=None, threshold=None):\n",
    "    \"\"\" Get model and input list \"\"\"\n",
    "    folder    = get_path(setup, model_type, pc_alpha=pc_alpha, threshold=threshold)\n",
    "    filename  = get_filename(setup, output)\n",
    "    \n",
    "    modelname = Path(folder,filename+'_model.h5')\n",
    "    print(f\"Load model: {modelname}\")\n",
    "    model     = load_model(modelname, compile=False)\n",
    "    \n",
    "    inputs_path = Path(folder, f\"{filename}_input_list.txt\")\n",
    "    with open(inputs_path) as inputs_file:\n",
    "        input_indices = [i for i, v in enumerate(inputs_file.readlines()) if int(v)]\n",
    "\n",
    "    return (model, input_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_list(setup, target_vars):\n",
    "    output_list = list()\n",
    "    for spcam_var in target_vars:\n",
    "        if spcam_var.dimensions == 3:\n",
    "            var_levels = [setup.children_idx_levs,setup.parents_idx_levs]\\\n",
    "            [spcam_var.type == 'in']\n",
    "            for level, _ in var_levels:\n",
    "                # There's enough info to build a Variable_Lev_Metadata list\n",
    "                # However, it could be better to do a bigger reorganization\n",
    "                var_name = f\"{spcam_var.name}-{round(level, 2)}\"\n",
    "                output_list.append(var_name)\n",
    "        elif spcam_var.dimensions == 2:\n",
    "            var_name = spcam_var.name\n",
    "            output_list.append(var_name)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.variable import Variable_Lev_Metadata\n",
    "import collections\n",
    "def load_models(setup):\n",
    "    \"\"\" Load all NN models specified in setup \"\"\"\n",
    "    models = collections.defaultdict(dict)\n",
    "    \n",
    "    output_list = get_var_list(setup, setup.spcam_outputs)\n",
    "    if setup.do_single_nn:\n",
    "        for output in output_list:\n",
    "            output = Variable_Lev_Metadata.parse_var_name(output)\n",
    "            models['SingleNN'][output] = get_model(\n",
    "                setup, \n",
    "                output, \n",
    "                'SingleNN',\n",
    "                pc_alpha=None,\n",
    "                threshold=None\n",
    "            )\n",
    "    if setup.do_causal_single_nn:\n",
    "        for pc_alpha in setup.pc_alphas:\n",
    "            models['CausalSingleNN'][pc_alpha] = {}\n",
    "            for threshold in setup.thresholds:\n",
    "                models['CausalSingleNN'][pc_alpha][threshold] = {}\n",
    "                for output in output_list:\n",
    "                    output = Variable_Lev_Metadata.parse_var_name(output)\n",
    "                    models['CausalSingleNN'][pc_alpha][threshold][output] = get_model(\n",
    "                        setup, \n",
    "                        output, \n",
    "                        'CausalSingleNN',\n",
    "                        pc_alpha=pc_alpha, \n",
    "                        threshold=threshold\n",
    "                    )\n",
    "                    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_models(setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.variable                        import Variable_Lev_Metadata\n",
    "from neural_networks.data_generator        import build_valid_generator\n",
    "from neural_networks.cbrain.utils          import load_pickle\n",
    "import numpy                               as     np\n",
    "import matplotlib.pyplot                   as     plt\n",
    "\n",
    "cThemes = {'tphystnd':'coolwarm',\n",
    "           'phq':'coolwarm',\n",
    "           'fsns':'Reds',\n",
    "           'flns':'Reds',\n",
    "           'fsnt':'Reds',\n",
    "           'flnt':'Reds',\n",
    "           'prect':'PuBu'}\n",
    "\n",
    "class ModelDiagnostics():\n",
    "    def __init__(self, setup, models, nlat=64, nlon=128, nlev=30, ntime=48):\n",
    "\n",
    "        self.nlat, self.nlon, self.nlev = nlat, nlon, nlev\n",
    "        self.ngeo                       = nlat * nlon\n",
    "        self.setup                      = setup\n",
    "        self.models                     = models\n",
    "\n",
    "    def reshape_ngeo(self, x):\n",
    "        return x.reshape(self.nlat, self.nlon, -1)\n",
    "\n",
    "    def get_output_var_idx(self, var):\n",
    "        var_idxs = self.valid_gen.norm_ds.var_names[self.valid_gen.output_idxs]\n",
    "        var_idxs = np.where(var_idxs == var)[0]\n",
    "        return var_idxs\n",
    "    \n",
    "\n",
    "    def get_truth_pred(self, itime, var, nTime=False):\n",
    "        \n",
    "        input_list  = get_var_list(self.setup, self.setup.spcam_inputs)\n",
    "        self.inputs = sorted(\n",
    "            [Variable_Lev_Metadata.parse_var_name(p) for p in input_list],\n",
    "            key=lambda x: self.setup.input_order_list.index(x),\n",
    "        )\n",
    "        self.input_vars_dict  = ModelDiagnostics._build_vars_dict(self.inputs)\n",
    "        \n",
    "        self.output = Variable_Lev_Metadata.parse_var_name(var)\n",
    "        self.output_vars_dict = ModelDiagnostics._build_vars_dict([self.output])\n",
    "        \n",
    "        self.valid_gen       = build_valid_generator(\n",
    "            self.input_vars_dict, \n",
    "            self.output_vars_dict, \n",
    "            self.setup\n",
    "        )\n",
    "        with self.valid_gen as valid_gen:\n",
    "            \n",
    "            model, inputs = self.models[var]\n",
    "            \n",
    "            if isinstance(itime, int):\n",
    "                X, truth = valid_gen[itime]\n",
    "                pred = model.predict_on_batch(X[:, inputs])\n",
    "            \n",
    "            elif itime == 'mean':\n",
    "                if not nTime:\n",
    "                    nTime = len(self.valid_gen)\n",
    "                truth = np.zeros([nTime,self.ngeo,1])\n",
    "                pred  = np.zeros([nTime,self.ngeo,1])\n",
    "                for iTime in range(nTime):\n",
    "                    X_tmp, truth[iTime,:] = valid_gen[iTime]\n",
    "                    pred[iTime,:] = model.predict_on_batch(X_tmp[:, inputs])\n",
    "                truth = np.mean(truth,axis=0)\n",
    "                pred  = np.mean(pred,axis=0)\n",
    "            \n",
    "            # Inverse transform\n",
    "            truth = valid_gen.output_transform.inverse_transform(truth)\n",
    "            pred = valid_gen.output_transform.inverse_transform(pred)\n",
    "\n",
    "        var_idxs = self.get_output_var_idx(var.var.ds_name)\n",
    "\n",
    "        truth = truth[:, var_idxs]\n",
    "        pred  = pred[:, var_idxs]\n",
    "        \n",
    "        return self.reshape_ngeo(truth), self.reshape_ngeo(pred)\n",
    "\n",
    "    \n",
    "    # Plotting functions\n",
    "    def plot_double_xy(\n",
    "        self, \n",
    "        itime, \n",
    "        var,\n",
    "        nTime=None, \n",
    "        save=None, \n",
    "        diff=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        varname = var.var.value\n",
    "        \n",
    "        t, p = self.get_truth_pred(itime, var, nTime=nTime)\n",
    "        \"\"\"THIS COULD GO INTO get_truth_pred!\"\"\"\n",
    "        if t.shape[2] == 1 and p.shape[2] == 1:\n",
    "            t = t.reshape(t.shape[:2])\n",
    "            p = p.reshape(p.shape[:2])\n",
    "        \n",
    "        return self.plot_slices(t, p, itime, varname=varname, save=save, diff=diff, **kwargs)\n",
    "\n",
    "\n",
    "    def plot_double_yz(\n",
    "        self, \n",
    "        itime, \n",
    "        ilon, \n",
    "        var,\n",
    "        varkeys,\n",
    "        nTime=None, \n",
    "        save=None, \n",
    "        diff=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        varname = var.var.value\n",
    "        \n",
    "        # Allocate array\n",
    "        truth = np.zeros([self.nlev, self.nlat])\n",
    "        pred  = np.zeros([self.nlev, self.nlat])\n",
    "        for var in varkeys:\n",
    "            iLev = ModelDiagnostics._build_vars_dict([var])[var.var.value.upper()][0]\n",
    "#            print(var, iLev)\n",
    "            t, p = self.get_truth_pred(itime, var, nTime=nTime)\n",
    "            \"\"\"THIS COULD GO INTO get_truth_pred!\"\"\"\n",
    "            if t.shape[2] == 1 and p.shape[2] == 1:\n",
    "                t = t.reshape(t.shape[:2])\n",
    "                p = p.reshape(p.shape[:2])\n",
    "            if isinstance(ilon, int):\n",
    "                truth[iLev,:] = t[:,ilon]\n",
    "                pred[iLev,:]  = p[:,ilon]\n",
    "            elif ilon == 'mean':\n",
    "                truth[iLev,:] = np.mean(t, axis=1)\n",
    "                pred[iLev,:]  = np.mean(p, axis=1)\n",
    "\n",
    "        return self.plot_slices(truth, pred, itime, varname=varname, save=save, diff=diff, **kwargs)\n",
    "    \n",
    "    \n",
    "    def plot_slices(\n",
    "        self, \n",
    "        t, \n",
    "        p, \n",
    "        itime, \n",
    "        title='', \n",
    "        unit='', \n",
    "        varname='', \n",
    "        save=None,\n",
    "        diff=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        n_slices  = [3,2][diff == None]\n",
    "        fig, axes = plt.subplots(1, n_slices, figsize=(12, 5))\n",
    "        \n",
    "        vmin = np.min([np.min(p),np.min(t)])\n",
    "        vmax = np.max([np.max(p),np.max(t)])\n",
    "        if varname in ['tphystnd','phq']:\n",
    "            vlim = np.max([np.abs(vmin),np.abs(vmax)])/2.\n",
    "            vmin = -vlim; vmax = vlim\n",
    "        elif varname in ['fsns','fsnt','prect']:\n",
    "            vmin = 0\n",
    "\n",
    "        cmap = cThemes[varname]\n",
    "        cmap_diff = 'coolwarm'\n",
    "        \n",
    "        vars_to_plot = [p, t, p-t]\n",
    "        labs_to_plot = ['Prediction', 'SPCAM', 'Prediction - SPCAM']\n",
    "        for iSlice in range(n_slices):\n",
    "            var_to_plot = vars_to_plot[iSlice]\n",
    "            lab_to_plot = labs_to_plot[iSlice]\n",
    "            I  = axes[iSlice].imshow(\n",
    "                var_to_plot, \n",
    "#                 vmin=[vmin,None][iSlice==2],\n",
    "#                 vmax=[vmax,None][iSlice==2],\n",
    "                vmin=vmin,\n",
    "                vmax=vmax, \n",
    "                cmap=[cmap,cmap_diff][iSlice==2], \n",
    "                **kwargs\n",
    "            )\n",
    "            cb = fig.colorbar(I, ax=axes[iSlice], orientation='horizontal')\n",
    "            cb.set_label(unit)\n",
    "            axes[iSlice].set_title(lab_to_plot)\n",
    "        \n",
    "        fig.suptitle(title)\n",
    "        if save is not None:\n",
    "            Path(save).mkdir(parents=True, exist_ok=True)\n",
    "            fig.savefig(f\"{save}/{var}_map_time-{itime}.png\")\n",
    "        return fig, axes\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _build_vars_dict(list_variables):\n",
    "        \"\"\" Convert the given list of Variable_Lev_Metadata into a\n",
    "        dictionary to be used on the data generator.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        list_variables : list(Variable_Lev_Metadata)\n",
    "            List of variables to be converted to the dictionary format\n",
    "            used by the data generator\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        vars_dict : dict{str : list(int)}\n",
    "            Dictionary of the form {ds_name : list of levels}, where\n",
    "            \"ds_name\" is the name of the variable as stored in the\n",
    "            dataset, and \"list of levels\" a list containing the indices\n",
    "            of the levels of that variable to use, or None for 2D\n",
    "            variables.\n",
    "        \"\"\"\n",
    "        vars_dict = dict()\n",
    "        for variable in list_variables:\n",
    "            ds_name = variable.var.ds_name  # Name used in the dataset\n",
    "            if variable.var.dimensions == 2:\n",
    "                vars_dict[ds_name] = None\n",
    "            elif variable.var.dimensions == 3:\n",
    "                levels = vars_dict.get(ds_name, list())\n",
    "                levels.append(variable.level_idx)\n",
    "                vars_dict[ds_name] = levels\n",
    "        return vars_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-section plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'SingleNN'\n",
    "md = ModelDiagnostics(setup = setup, models=models[model_type])\n",
    "vars_to_ploted = []\n",
    "for var in models[model_type].keys():\n",
    "    if var.var.value not in vars_to_ploted and var.var.dimensions == 3:\n",
    "        print(var.var.value)\n",
    "        outPath = get_save_plot_folder(setup, model_type, var.var.value)\n",
    "        var_keys = [v for v in models[model_type].keys() if var.var.value in str(v)]\n",
    "        md.plot_double_yz(100, 100, var, var_keys, nTime=False, diff=True)\n",
    "#        md.plot_double_yz('mean', 'mean', var, var_keys, nTime=30, diff=True)\n",
    "        vars_to_ploted.append(var.var.value)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'CausalSingleNN'\n",
    "vars_to_ploted = []\n",
    "for pc_alpha in models[model_type].keys():\n",
    "    print(f\"pc_alpha: {pc_alpha}\")\n",
    "    for threshold in models[model_type][pc_alpha].keys():\n",
    "        print(f\"threshold: {threshold}\")\n",
    "        md = ModelDiagnostics(setup = setup, models=models[model_type][pc_alpha][threshold])\n",
    "        for var in models[model_type][pc_alpha][threshold].keys():\n",
    "            if var.var.value not in vars_to_ploted and var.var.dimensions == 3:\n",
    "                print(var.var.value)\n",
    "                outPath = get_save_plot_folder(setup, model_type, var.var.value)\n",
    "                var_keys = [v for v in models[model_type][pc_alpha][threshold].keys() \\\n",
    "                            if var.var.value in str(v)]\n",
    "                md.plot_double_yz(100, 100, var, var_keys, nTime=False, diff=True)\n",
    "#                md.plot_double_yz('mean', 'mean', var, var_keys, nTime=30, diff=True)\n",
    "                vars_to_ploted.append(var.var.value)\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'SingleNN'\n",
    "md = ModelDiagnostics(setup = setup, models=models[model_type])\n",
    "for var in models[model_type].keys():\n",
    "    print(var)\n",
    "    outPath = get_save_plot_folder(setup, model_type, var)\n",
    "#    md.plot_double_xy('mean', var, nTime=False, diff=True, save=outPath)\n",
    "    md.plot_double_xy(100, var, nTime=False, diff=True)#, save=outPath)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'CausalSingleNN'\n",
    "for pc_alpha in models[model_type].keys():\n",
    "    print(f\"pc_alpha: {pc_alpha}\")\n",
    "    for threshold in models[model_type][pc_alpha].keys():\n",
    "        print(f\"threshold: {threshold}\")\n",
    "        md = ModelDiagnostics(setup = setup, models=models[model_type][pc_alpha][threshold])\n",
    "        for var in models[model_type][pc_alpha][threshold].keys():\n",
    "            print(f\"variable: {var}\\n\")\n",
    "            md.plot_double_xy(100, var)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalnncam",
   "language": "python",
   "name": "causalnncam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
