{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Load results files and run analysis on them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import utils.utils as utils\n",
    "from utils.plotting import plot_links, find_linked_variables\n",
    "\n",
    "from utils.setup import Setup\n",
    "\n",
    "argv           = sys.argv[1:]\n",
    "# argv           = ['-c', 'cfg_pipeline.yml']\n",
    "# argv           = ['-c', 'cfg_concat_lon120.yml']\n",
    "# argv           = ['-c', 'cfg_single_lon120.yml']\n",
    "\n",
    "setup = Setup(argv)\n",
    "\n",
    "Path(setup.plots_folder).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parents_from_links(links):\n",
    "    linked_variables = set() # Avoids duplicates and sorts when list\n",
    "    for parents_list in links.values():\n",
    "        if len(parents_list) > 0:\n",
    "            linked_variables.add(child)\n",
    "            for parent in parents_list:\n",
    "                linked_variables.add(parent[0])\n",
    "    return [(i in linked_variables)  for i in range(len(links))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_error(file, error_type, errors):\n",
    "    error_list = errors.get(error_type, list())\n",
    "    if file not in error_list:\n",
    "        error_list.append(results_file)\n",
    "        errors[error_type] = error_list\n",
    "\n",
    "def aggregate_results(key, results_file, aggregated_results, setup, errors):\n",
    "    aggregated_pc_alpha = aggregated_results.get(key, dict())\n",
    "    if not results_file.is_file():\n",
    "        add_error(results_file, \"not_found\", errors)\n",
    "        return\n",
    "    results = utils.load_results(results_file)\n",
    "    for pc_alpha, alpha_result in results.items():\n",
    "        if len(alpha_result) > 0:\n",
    "            aggregated = aggregated_pc_alpha.get(pc_alpha, dict())\n",
    "            aggregated_pc_alpha[pc_alpha] = aggregated\n",
    "            # Aggregate parents\n",
    "            links = alpha_result[\"links\"]\n",
    "            parents = get_parents_from_links(links)\n",
    "            aggregated_parents = aggregated.get(\"parents\", list())\n",
    "            aggregated_parents.append(parents)\n",
    "            aggregated[\"parents\"] = aggregated_parents\n",
    "            # Aggregate val_matrix\n",
    "            val_matrix = alpha_result[\"val_matrix\"]\n",
    "            aggregated_val_matrix = aggregated.get(\"val_matrix\", list())\n",
    "            aggregated_val_matrix.append(val_matrix)\n",
    "            aggregated[\"val_matrix\"] = aggregated_val_matrix\n",
    "            global var_names\n",
    "            var_names = alpha_result[\"var_names\"] # TODO Very uncomfortable way to obtain this data. Should be metadata\n",
    "        else:\n",
    "            add_error(results_file, \"is_empty\", errors)\n",
    "    aggregated_results[key] = aggregated_pc_alpha\n",
    "    # Doesn't return, instead modifies the received `aggregated results` object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_variables(var_children, levels):\n",
    "    total = 0\n",
    "    for child in var_children:\n",
    "        if child.dimensions == 2:\n",
    "            total += 1\n",
    "        elif child.dimensions == 3:\n",
    "            total += len(levels)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "KEY_PATTERN = \"{var_name}-{level}\"\n",
    "\n",
    "aggregated_results = dict()\n",
    "errors = dict()\n",
    "\n",
    "total_vars = count_total_variables(\n",
    "    setup.var_children, setup.children_idx_levs)\n",
    "total_files = total_vars * len(setup.gridpoints)\n",
    "file_progress = 0\n",
    "step_progress = 1\n",
    "step = 5\n",
    "\n",
    "for child in setup.var_children:\n",
    "    print(f\"Variable: {child.name}\")\n",
    "    \n",
    "    if child.dimensions == 2:\n",
    "        child_levels = [[setup.levels[-1],0]]\n",
    "        key = child.name\n",
    "    elif child.dimensions == 3:\n",
    "        child_levels = setup.children_idx_levs\n",
    "    for level in child_levels:      \n",
    "        if child.dimensions == 3:\n",
    "            key = KEY_PATTERN.format(\n",
    "                    var_name = child.name,\n",
    "                    level = round(level[0], 2)\n",
    "            )\n",
    "        if setup.analysis == \"single\":\n",
    "            for i_grid, (lat, lon) in enumerate(setup.gridpoints):\n",
    "                results_file = utils.generate_results_filename_single(\n",
    "                        child, level[1], lat, lon, setup.ind_test_name,\n",
    "                        setup.experiment, setup.output_file_pattern,\n",
    "                        setup.output_folder)\n",
    "                aggregate_results(\n",
    "                        key, results_file, aggregated_results, setup, errors)\n",
    "        elif setup.analysis == \"concat\":\n",
    "            results_file = utils.generate_results_filename_concat(\n",
    "                    child, level[-1], setup.gridpoints, setup.ind_test_name,\n",
    "                    setup.experiment, setup.output_file_pattern,\n",
    "                    setup.output_folder)\n",
    "            aggregate_results(\n",
    "                    key, results_file, aggregated_results, setup, errors)\n",
    "        \n",
    "        file_progress += len(setup.gridpoints)\n",
    "        if(file_progress == total_files or\n",
    "           ((file_progress / total_files * 100) >= step * step_progress)):\n",
    "            step_progress += 1\n",
    "            print(\"Progress: {:.2f}% - {} of {} files\".format(\n",
    "                    file_progress / total_files * 100,\n",
    "                    file_progress,\n",
    "                    total_files\n",
    "                ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print errors found loading aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ERRORS\\n======\")\n",
    "for error_type, error_list in errors.items():\n",
    "    msg = \"{}: {} of {} files ({:.2f}%)\".format(\n",
    "            error_type,\n",
    "            len(error_list),\n",
    "            total_files,\n",
    "            len(error_list)/total_files*100\n",
    "    )\n",
    "    print(msg)\n",
    "    print(\"-\" * len(msg))\n",
    "    for file in error_list:\n",
    "        print(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# thresholds = [.2, .3, .5, .6]\n",
    "thresholds = [.3, .5]\n",
    "# thresholds = [1]\n",
    "pc_alphas_filter = [str(a) for a in [.001, .01, .1]]\n",
    "var_names_np = np.array(var_names)\n",
    "\n",
    "# Combine results\n",
    "dict_child_parents = dict()\n",
    "for child, aggregated_pc_alpha in aggregated_results.items():\n",
    "    dict_pc_alpha_parents = dict()\n",
    "    for pc_alpha, aggregated in aggregated_pc_alpha.items():\n",
    "        dict_threshold_parents = dict()\n",
    "        if pc_alpha not in pc_alphas_filter:\n",
    "            continue # Skip this pc alpha\n",
    "        parents_matrix = aggregated[\"parents\"]\n",
    "        parents_matrix = np.array(parents_matrix)\n",
    "        parents_percent = parents_matrix.mean(axis=0)\n",
    "        \n",
    "        val_matrix_list = np.array(aggregated[\"val_matrix\"])\n",
    "        val_matrix_mean = val_matrix_list.mean(axis = 0)\n",
    "        for threshold in thresholds:\n",
    "            parents_filtered = parents_percent >= threshold\n",
    "            parents = [i for i in range(len(parents_filtered)) if parents_filtered[i]]\n",
    "            dict_threshold_parents[str(threshold)] = parents\n",
    "        dict_pc_alpha_parents[pc_alpha] = {\n",
    "                \"parents\" : dict_threshold_parents,\n",
    "                \"val_matrix\" : val_matrix_mean,\n",
    "                \"parents_percent\" : parents_percent\n",
    "        }\n",
    "            \n",
    "    dict_child_parents[child] = dict_pc_alpha_parents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print combined results\n",
    "for child, dict_pc_alpha_parents in dict_child_parents.items():\n",
    "    print(f\"\\n{child}\")\n",
    "    for pc_alpha, pc_alpha_results in dict_pc_alpha_parents.items():\n",
    "        if pc_alpha not in pc_alphas_filter:\n",
    "            continue # Skip this pc alpha\n",
    "        print(f\"pc_alpha = {pc_alpha}\")\n",
    "        dict_threshold_parents = pc_alpha_results[\"parents\"]\n",
    "        for threshold, parents in dict_threshold_parents.items():\n",
    "            print(f\"* Threshold {threshold}:\\t{var_names_np[parents]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for each pc_alpha and threshold combination with all children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate results file for filter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names_parents = var_names[:-1] # NOTE: This assumes that the list has only one child\n",
    "len_parents = len(var_names_parents)\n",
    "len_total = len_parents + len(dict_child_parents)\n",
    "\n",
    "dict_full = dict()\n",
    "for i_child, (child, dict_pc_alpha_parents) in enumerate(\n",
    "        dict_child_parents.items()):\n",
    "    i_child = i_child + len_parents\n",
    "    for pc_alpha, pc_alpha_results in dict_pc_alpha_parents.items():\n",
    "        dict_pc_alpha_full = dict_full.get(pc_alpha, dict())\n",
    "        dict_full[pc_alpha] = dict_pc_alpha_full\n",
    "        \n",
    "        # Build val_matrix (only from inputs to outputs)\n",
    "        pc_alpha_val_matrix = pc_alpha_results[\"val_matrix\"]\n",
    "        full_val_matrix = dict_pc_alpha_full.get(\n",
    "                \"val_matrix\", np.zeros((len_total, len_total, 1)))\n",
    "        full_val_matrix[:len_parents, i_child, 0] = pc_alpha_val_matrix[\n",
    "                :len_parents,-1,1]\n",
    "        dict_pc_alpha_full[\"val_matrix\"] = full_val_matrix\n",
    "        \n",
    "        # Build link_width\n",
    "        parents_percent = pc_alpha_results[\"parents_percent\"]\n",
    "        link_width = dict_pc_alpha_full.get(\n",
    "                \"link_width\", np.zeros((len_total, len_total, 1)))\n",
    "        link_width[:len_parents, i_child, 0] = parents_percent[:len_parents]\n",
    "        dict_pc_alpha_full[\"link_width\"] = link_width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combination:\n",
    "    \n",
    "    def __init__(self, pc_alpha, threshold):\n",
    "        self.pc_alpha = pc_alpha\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def __str__(self):\n",
    "        return repr(self)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"a{self.pc_alpha}-t{self.threshold}\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(repr(self))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return repr(self) == repr(other)\n",
    "\n",
    "\n",
    "var_names_parents = var_names[:-1] # NOTE: This assumes that the list has only one child\n",
    "var_names_children = list()\n",
    "\n",
    "dict_combinations = dict()\n",
    "len_parents = len(var_names_parents)\n",
    "len_total = len_parents + len(dict_child_parents)\n",
    "for i_child, (child, dict_pc_alpha_parents) in enumerate(\n",
    "        dict_child_parents.items()):\n",
    "    i_child = i_child + len_parents\n",
    "    var_names_children.append(child)\n",
    "    for pc_alpha, pc_alpha_results in dict_pc_alpha_parents.items():        \n",
    "        dict_threshold_parents = pc_alpha_results[\"parents\"]\n",
    "        for threshold, parents in dict_threshold_parents.items():\n",
    "            key = Combination(pc_alpha, threshold)\n",
    "            combination_results = dict_combinations.get(key, dict())\n",
    "            \n",
    "            # Build links\n",
    "            links = combination_results.get(\n",
    "                    \"links\", {i : [] for i in range(len_total)})\n",
    "            links[i_child] = [(parent, 0) for parent in parents]\n",
    "            combination_results[\"links\"] = links\n",
    "            \n",
    "            # Store results\n",
    "            dict_combinations[key] = combination_results\n",
    "\n",
    "all_var_names = var_names_parents + var_names_children # Concatenation\n",
    "for combination, combination_results in dict_combinations.items():\n",
    "    val_matrix = dict_full[combination.pc_alpha][\"val_matrix\"]\n",
    "    combination_results[\"val_matrix\"] = val_matrix\n",
    "    link_width = dict_full[combination.pc_alpha][\"link_width\"]\n",
    "    combination_results[\"link_width\"] = link_width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_sizes(links):\n",
    "    linked_variables = find_linked_variables(links)\n",
    "    n_linked_vars = len(linked_variables)\n",
    "    print(f\"n_linked_vars : {n_linked_vars}\")\n",
    "    if n_linked_vars <= 35:\n",
    "        # Small\n",
    "        figsize = (16, 16)\n",
    "        node_size = 0.15\n",
    "    elif n_linked_vars <= 70:\n",
    "        # Medium\n",
    "        figsize = (32, 32)\n",
    "        node_size = 0.10\n",
    "    else:\n",
    "        #Big\n",
    "        figsize = (48, 48)\n",
    "        node_size = 0.05\n",
    "    \n",
    "    return figsize, node_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_val_matrix(val_matrix):\n",
    "    \"\"\"\n",
    "    Scales to values between -1 and 1, keeping zero in the same place\n",
    "    \"\"\"\n",
    "    max_val = np.abs(val_matrix).max()\n",
    "    return val_matrix/max_val\n",
    "\n",
    "\n",
    "def scale_link_width(o_link_width, threshold):\n",
    "    \"\"\"\n",
    "    Scales 0.05 (so links are drawn) and 1 range, taking the threshold\n",
    "    as the minimum\n",
    "    \"\"\"\n",
    "    min_val = threshold\n",
    "#     min_val = o_link_width[o_link_width >= threshold].min()\n",
    "    smallest_link = 0.05\n",
    "    link_width = o_link_width + smallest_link\n",
    "    link_width -= min_val\n",
    "    link_width[o_link_width < threshold] = 0 \n",
    "    return link_width/link_width.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combination, combination_results in dict_combinations.items():\n",
    "    print(combination)\n",
    "    plot_filename = \"{cfg}_{combination}.png\".format(\n",
    "            cfg = setup.yml_filename.rsplit(\".\")[0],\n",
    "            combination = combination\n",
    "    )\n",
    "    plot_file = Path(setup.plots_folder, plot_filename)\n",
    "    if not setup.overwrite and plot_file.is_file():\n",
    "        print(f\"Found file {plot_file}, skipping.\")\n",
    "        continue # Ignore this result\n",
    "    links = combination_results[\"links\"]\n",
    "    figsize, node_size = recommend_sizes(links)\n",
    "    \n",
    "    val_matrix = combination_results[\"val_matrix\"]\n",
    "    link_width = combination_results[\"link_width\"]\n",
    "    val_matrix = scale_val_matrix(val_matrix)\n",
    "    link_width = scale_link_width(\n",
    "            link_width, float(combination.threshold))\n",
    "    \n",
    "    plot_links(\n",
    "        links,\n",
    "        all_var_names,\n",
    "        val_matrix = val_matrix,\n",
    "        link_width = link_width,\n",
    "        arrow_linewidth = 10,\n",
    "        save_name = plot_file,\n",
    "        figsize = figsize,\n",
    "        node_size = node_size\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tigramite",
   "language": "python",
   "name": "tigramite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
