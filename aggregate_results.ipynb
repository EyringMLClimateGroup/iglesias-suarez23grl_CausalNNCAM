{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Load results files and run analysis on them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import utils.utils as utils\n",
    "from utils.plotting import plot_links\n",
    "\n",
    "from utils.setup import Setup\n",
    "\n",
    "argv           = sys.argv[1:]\n",
    "# argv           = ['-c', 'cfg_pipeline.yml']\n",
    "# argv           = ['-c', 'cfg_concat_lon120.yml']\n",
    "# argv           = ['-c', 'cfg_single_lon120.yml']\n",
    "\n",
    "setup = Setup(argv)\n",
    "\n",
    "Path(setup.plots_folder).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parents_from_links(links):\n",
    "    linked_variables = set() # Avoids duplicates and sorts when list\n",
    "    for parents_list in links.values():\n",
    "        if len(parents_list) > 0:\n",
    "            linked_variables.add(child)\n",
    "            for parent in parents_list:\n",
    "                linked_variables.add(parent[0])\n",
    "    return [(i in linked_variables)  for i in range(len(links))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results_single(key, aggregated_results, setup, errors):\n",
    "    for i_grid, (lat, lon) in enumerate(setup.gridpoints):\n",
    "        aggregated_pc_alpha = aggregated_results.get(key, dict())\n",
    "        results_file = utils.generate_results_filename_single(\n",
    "                child, level[1], lat, lon, setup.experiment,\n",
    "                setup.output_file_pattern, setup.output_folder)\n",
    "        if not results_file.is_file():\n",
    "#             print(f\"Results file {results_file} not found, skipping.\")\n",
    "            not_found_list = errors.get(\"not_found\", list())\n",
    "            if results_file not in not_found_list:\n",
    "                not_found_list.append(results_file)\n",
    "                errors[\"not_found\"] = not_found_list\n",
    "            continue\n",
    "        results = utils.load_results(results_file)\n",
    "        for pc_alpha, alpha_result in results.items():\n",
    "            if len(alpha_result) > 0:\n",
    "                links = alpha_result[\"links\"]\n",
    "                parents = get_parents_from_links(links)\n",
    "                aggregated = aggregated_pc_alpha.get(pc_alpha, list())\n",
    "                aggregated.append(parents)\n",
    "                aggregated_pc_alpha[pc_alpha] = aggregated\n",
    "                global var_names\n",
    "                var_names = alpha_result[\"var_names\"] # TODO Very uncomfortable way to obtain this data. Should be metadata\n",
    "            else:\n",
    "#                 print(f\"File {results_file} is empty, skipping.\") # Prints too often\n",
    "                is_empty_list = errors.get(\"is_empty\", list())\n",
    "                if results_file not in is_empty_list:\n",
    "                    is_empty_list.append(results_file)\n",
    "                    errors[\"is_empty\"] = is_empty_list\n",
    "        aggregated_results[key] = aggregated_pc_alpha\n",
    "    # Doesn't return, instead modifies the received `aggregated results` object\n",
    "\n",
    "    \n",
    "def aggregate_results_concat(key, aggregated_results, setup, errors):\n",
    "    aggregated_pc_alpha = aggregated_results.get(key, dict())\n",
    "    results_file = utils.generate_results_filename_concat(\n",
    "            child, level[-1], setup.gridpoints, setup.experiment,\n",
    "            setup.output_file_pattern, setup.output_folder)\n",
    "    if not results_file.is_file():\n",
    "#         print(f\"Results file {results_file} not found, skipping.\")\n",
    "        not_found_list = errors.get(\"not_found\", list())\n",
    "        if results_file not in not_found_list:\n",
    "            not_found_list.append(results_file)\n",
    "            errors[\"not_found\"] = not_found_list\n",
    "        return\n",
    "    results = utils.load_results(results_file)\n",
    "    for pc_alpha, alpha_result in results.items():\n",
    "        if len(alpha_result) > 0:\n",
    "            links = alpha_result[\"links\"]\n",
    "            parents = get_parents_from_links(links)\n",
    "            aggregated = aggregated_pc_alpha.get(pc_alpha, list())\n",
    "            aggregated.append(parents)\n",
    "            aggregated_pc_alpha[pc_alpha] = aggregated\n",
    "            global var_names\n",
    "            var_names = alpha_result[\"var_names\"] # TODO Very uncomfortable way to obtain this data. Should be metadata\n",
    "        else:\n",
    "#             print(f\"File {results_file} is empty, skipping.\") # Prints too often\n",
    "            is_empty_list = errors.get(\"is_empty\", list())\n",
    "            if results_file not in is_empty_list:\n",
    "                is_empty_list.append(results_file)\n",
    "                errors[\"is_empty\"] = is_empty_list\n",
    "    aggregated_results[key] = aggregated_pc_alpha\n",
    "    # Doesn't return, instead modifies the received `aggregated results` object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_variables(var_children, levels):\n",
    "    total = 0\n",
    "    for child in var_children:\n",
    "        if child.dimensions == 2:\n",
    "            total += 1\n",
    "        elif child.dimensions == 3:\n",
    "            total += len(levels)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "KEY_PATTERN = \"{var_name}-{level}\"\n",
    "\n",
    "aggregated_results = dict()\n",
    "errors = dict()\n",
    "\n",
    "total_vars = count_total_variables(\n",
    "    setup.var_children, setup.children_idx_levs)\n",
    "total_files = total_vars * len(setup.gridpoints)\n",
    "file_progress = 0\n",
    "step_progress = 1\n",
    "step = 5\n",
    "\n",
    "for child in setup.var_children:\n",
    "    print(f\"Variable: {child.name}\")\n",
    "    \n",
    "    if child.dimensions == 2:\n",
    "        child_levels = [[setup.levels[-1],0]]\n",
    "        key = child.name\n",
    "    elif child.dimensions == 3:\n",
    "        child_levels = setup.children_idx_levs\n",
    "    for level in child_levels:      \n",
    "        if child.dimensions == 3:\n",
    "            key = KEY_PATTERN.format(\n",
    "                    var_name = child.name,\n",
    "                    level = round(level[0], 2)\n",
    "            )\n",
    "        if setup.analysis == \"single\":\n",
    "            aggregate_results_single(\n",
    "                key, aggregated_results, setup, errors)\n",
    "        elif setup.analysis == \"concat\":\n",
    "            aggregate_results_concat(\n",
    "                key, aggregated_results, setup, errors)\n",
    "        \n",
    "        file_progress += len(setup.gridpoints)\n",
    "        if(file_progress == total_files or\n",
    "           ((file_progress / total_files * 100) >= step * step_progress)):\n",
    "            step_progress += 1\n",
    "            print(\"Progress: {:.2f}% - {} of {} files\".format(\n",
    "                    file_progress / total_files * 100,\n",
    "                    file_progress,\n",
    "                    total_files\n",
    "                ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print errors found loading aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ERRORS\\n======\")\n",
    "for error_type, error_list in errors.items():\n",
    "    msg = \"{}: {} of {} files ({:.2f}%)\".format(\n",
    "            error_type,\n",
    "            len(error_list),\n",
    "            total_files,\n",
    "            len(error_list)/total_files*100\n",
    "    )\n",
    "    print(msg)\n",
    "    print(\"-\" * len(msg))\n",
    "    for file in error_list:\n",
    "        print(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# thresholds = [.2, .3, .5, .6]\n",
    "thresholds = [.3, .5]\n",
    "# thresholds = [1]\n",
    "pc_alphas_filter = [str(a) for a in [.001, .01, .1]]\n",
    "var_names_np = np.array(var_names)\n",
    "\n",
    "# Print analysis\n",
    "dict_child_parents = dict()\n",
    "for child, result in aggregated_results.items():\n",
    "    print(f\"\\n{child}\")\n",
    "    dict_pc_alpha_parents = dict()\n",
    "    for pc_alpha, parents_matrix in result.items():\n",
    "        dict_threshold_parents = dict()\n",
    "        if pc_alpha not in pc_alphas_filter:\n",
    "            continue # Skip this pc alpha\n",
    "        parents_matrix = np.array(parents_matrix)\n",
    "        parents_percent = parents_matrix.sum(axis = 0) / parents_matrix.shape[0]\n",
    "#         dict_pc_alpha_parents[\"percent\"] = parents_percent\n",
    "        print(f\"pc_alpha = {pc_alpha}\")\n",
    "        for threshold in thresholds:\n",
    "            parents_filtered = parents_percent >= threshold\n",
    "            parents = [i for i in range(len(parents_filtered)) if parents_filtered[i]]\n",
    "#             print(parents_filtered)\n",
    "#             print(parents)\n",
    "            dict_threshold_parents[str(threshold)] = parents\n",
    "            print(f\"* Threshold {threshold}:\\t{var_names_np[parents]}\")\n",
    "        dict_pc_alpha_parents[pc_alpha] = dict_threshold_parents\n",
    "    dict_child_parents[child] = dict_pc_alpha_parents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for each pc_alpha and threshold combination with all children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate results file for filter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names_parents = var_names[:-1] # NOTE: This assumes that the list has only one child\n",
    "var_names_children = list()\n",
    "\n",
    "dict_combinations = dict()\n",
    "len_parents = len(var_names_parents)\n",
    "len_total = len_parents + len(dict_child_parents)\n",
    "for i_child, (child, dict_pc_alpha_parents) in enumerate(dict_child_parents.items()):\n",
    "    i_child = i_child + len_parents\n",
    "    var_names_children.append(child)\n",
    "    for pc_alpha, dict_threshold_parents in dict_pc_alpha_parents.items():\n",
    "        for threshold, parents in dict_threshold_parents.items():\n",
    "            key = f\"a{pc_alpha}-t{threshold}\"\n",
    "            combination_results = dict_combinations.get(key, dict())\n",
    "            \n",
    "            # Build links\n",
    "            links = combination_results.get(\n",
    "                    \"links\", {i : [] for i in range(len(var_names_parents))})\n",
    "#             links[i_child] = [(parent, -1) for parent in parents]\n",
    "            links[i_child] = [(parent, 0) for parent in parents]\n",
    "            combination_results[\"links\"] = links\n",
    "            \n",
    "            # Build link_matrix\n",
    "            link_matrix = combination_results.get(\n",
    "                    \"link_matrix\",\n",
    "#                     [[[False, False] for i in range(len_total)]\n",
    "                    [[[False] for i in range(len_total)]\n",
    "                         for j in range(len_total)])\n",
    "            for parent in parents:\n",
    "#                 link_matrix[parent][i_child] = [False, True]\n",
    "                link_matrix[parent][i_child] = [True]\n",
    "            combination_results[\"link_matrix\"] = link_matrix\n",
    "            \n",
    "            # Store results\n",
    "            dict_combinations[key] = combination_results\n",
    "\n",
    "all_var_names = var_names_parents + var_names_children # Concatenation\n",
    "for combination, combination_results in dict_combinations.items():\n",
    "    combination_results[\"link_matrix\"] = np.array(combination_results[\"link_matrix\"])\n",
    "    combination_results[\"var_names\"] = all_var_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combination, combination_results in dict_combinations.items():\n",
    "    print(combination)\n",
    "    plot_filename = \"{cfg}_{combination}.png\".format(\n",
    "            cfg = setup.yml_filename.rsplit(\".\")[0],\n",
    "            combination = combination\n",
    "    )\n",
    "    plot_file = Path(setup.plots_folder, plot_filename)\n",
    "    if not setup.overwrite and plot_file.is_file():\n",
    "        print(f\"Found file {plot_file}, skipping.\")\n",
    "        continue # Ignore this result\n",
    "    plot_links(\n",
    "        combination_results,\n",
    "        save_name = plot_file,\n",
    "        figsize = (48, 48),\n",
    "        node_size = 0.05\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tigramite",
   "language": "python",
   "name": "tigramite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
