{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***DESCRIPTION*** \n",
    "## ***Run Tigramite (PCMCI) for SPCAM data with specified settings:***\n",
    "### Fixed:\n",
    "- PC-stable (i.e., MCI component not run)\n",
    "- tau_min/tau_max = -1\n",
    "- Significance: analytics\n",
    "- experiments: '002_train_1_year'\n",
    "- links: parents (state fields) -> children (parameterizations)\n",
    "### Options:\n",
    "- children (parameterizations)\n",
    "- region: lat/lon limits (gridpoints to be used)\n",
    "- levels: children's levels to be explored\n",
    "- pc_alphas: list of value(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import sys, getopt, yaml, time, datetime\n",
    "from datetime import datetime as dt\n",
    "import numpy                  as np\n",
    "from pathlib              import Path\n",
    "\n",
    "# Utils\n",
    "from   utils.constants    import SPCAM_Vars, DATA_FOLDER, ANCIL_FILE, OUTPUT_FILE_PATTERN\n",
    "from   utils.constants    import tau_min, tau_max, significance, experiment\n",
    "import utils.utils            as utils\n",
    "import utils.links            as links\n",
    "import utils.pcmci_algorithm  as algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argv           = sys.argv[1:]\n",
    "# argv           = ['-c', 'cfg_pipeline.yml']\n",
    "try:\n",
    "    opts, args = getopt.getopt(argv,\"hc:a\",[\"cfg_file=\",\"add=\"])\n",
    "except getopt.GetoptError:\n",
    "    print ('pipeline.py -c [cfg_file] -a [add]')\n",
    "    sys.exit(2)\n",
    "for opt, arg in opts:\n",
    "    if opt == '-h':\n",
    "        print ('pipeline.py -c [cfg_file]')\n",
    "        sys.exit()\n",
    "    elif opt in (\"-c\", \"--cfg_file\"):\n",
    "        yml_cfgFilenm = arg\n",
    "    elif opt in (\"-a\", \"--add\"):\n",
    "        pass\n",
    "\n",
    "# YAML config file\n",
    "yml_cfgFile       = open(yml_cfgFilenm)\n",
    "yml_cfg           = yaml.load(yml_cfgFile, Loader=yaml.FullLoader)\n",
    "\n",
    "# Load specifications\n",
    "spcam_parents     = yml_cfg['spcam_parents']\n",
    "spcam_children    = yml_cfg['spcam_children']\n",
    "pc_alphas         = yml_cfg['pc_alphas']\n",
    "region            = yml_cfg['region']\n",
    "lim_levels        = yml_cfg['lim_levels']\n",
    "target_levels     = yml_cfg['target_levels']\n",
    "verbosity         = yml_cfg['verbosity']\n",
    "output_folder     = yml_cfg['output_folder']\n",
    "overwrite         = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Region / Gridpoints\n",
    "if region is False:\n",
    "    region     = [ [-90,90] , [0,-.5] ] # All\n",
    "gridpoints = utils.get_gridpoints(region)\n",
    "\n",
    "## Children levels (parents includes all)\n",
    "if lim_levels is not False and target_levels is False:\n",
    "    target_levels = utils.get_levels(lim_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model's grid\n",
    "levels, latitudes, longitudes = utils.read_ancilaries(\n",
    "        Path(DATA_FOLDER, ANCIL_FILE))\n",
    "\n",
    "## Latitude / Longitude indexes\n",
    "idx_lats = [utils.find_closest_value(latitudes, gridpoint[0])\n",
    "            for gridpoint in gridpoints]\n",
    "idx_lons = [utils.find_closest_longitude(longitudes, gridpoint[1])\n",
    "            for gridpoint in gridpoints]\n",
    "\n",
    "## Level indexes (children & parents)\n",
    "parents_idx_levs = [[round(lev, 2), i] for i, lev in enumerate(levels)] # All\n",
    "if target_levels is not False:\n",
    "    children_idx_levs = [[lev, utils.find_closest_value(levels, lev)]\n",
    "                         for lev in target_levels]\n",
    "else:\n",
    "    children_idx_levs = parents_idx_levs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables\n",
    "spcam_vars_include = spcam_parents + spcam_children\n",
    "SPCAM_Vars         = [var for var in SPCAM_Vars if var.label in spcam_vars_include]\n",
    "var_parents        = [var for var in SPCAM_Vars if var.type == \"in\"]\n",
    "var_children       = [var for var in SPCAM_Vars if var.type == \"out\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_grid = len(gridpoints)\n",
    "t_start = time.time()\n",
    "for i_grid, (lat, lon) in enumerate(gridpoints):\n",
    "    \n",
    "    t_start_gridpoint = time.time()\n",
    "    data_parents = None\n",
    "    \n",
    "    idx_lat = idx_lats[i_grid]\n",
    "    idx_lon = idx_lons[i_grid]\n",
    "    \n",
    "    for child in var_children:\n",
    "        print(f\"{dt.now()} Variable: {child.name}\")\n",
    "        if child.dimensions == 2:\n",
    "            child_levels = [[levels[-1],0]]\n",
    "        elif child.dimensions == 3:\n",
    "            child_levels = children_idx_levs\n",
    "        for level in child_levels:\n",
    "            \n",
    "            results_file = utils.generate_results_filename(\n",
    "                    child, level[-1], lat, lon, experiment, output_folder)\n",
    "            \n",
    "            if not overwrite and results_file.is_file():\n",
    "                print(f\"{dt.now()} Found file {results_file}, skipping.\")\n",
    "                continue # Ignore this level\n",
    "            \n",
    "            \n",
    "            # Only load parents if necessary to analyze a child\n",
    "            # they stay loaded until the next gridpoint\n",
    "            if data_parents is None:\n",
    "                \n",
    "                print(f\"{dt.now()} Gridpoint {i_grid+1}/{len_grid}: lat={lat}\"\n",
    "                      + f\" ({idx_lat}), lon={lon} ({idx_lon})\")\n",
    "                \n",
    "                print(f\"Load Parents (state fields)...\")\n",
    "                t_before_load_parents = time.time()\n",
    "                data_parents = utils.load_data(\n",
    "                    var_parents,\n",
    "                    experiment,\n",
    "                    DATA_FOLDER,\n",
    "                    parents_idx_levs,\n",
    "                    idx_lat,\n",
    "                    idx_lon)\n",
    "                time_load_parents = datetime.timedelta(\n",
    "                        seconds = time.time() - t_before_load_parents)\n",
    "                print(f\"{dt.now()} All parents loaded. Time: {time_load_parents}\")\n",
    "            \n",
    "            # Process child\n",
    "            data_child = utils.load_data([child],\n",
    "                                   experiment,\n",
    "                                   DATA_FOLDER,\n",
    "                                   [level],\n",
    "                                   idx_lat,\n",
    "                                   idx_lon)\n",
    "            data = [*data_parents, *data_child]\n",
    "            \n",
    "            # Find links\n",
    "            print(f\"{dt.now()} Finding links for {child.name} at level {level[-1]+1}\")\n",
    "            t_before_find_links = time.time()\n",
    "            results = algorithm.find_links(data, pc_alphas, 0)\n",
    "            time_links = datetime.timedelta(\n",
    "                    seconds = time.time() - t_before_find_links)\n",
    "            total_time = datetime.timedelta(seconds = time.time() - t_start)\n",
    "            print(f\"{dt.now()} Links found. Time: {time_links}\"\n",
    "                  + f\" Total time so far: {total_time}\")\n",
    "\n",
    "            # Store causal links\n",
    "            utils.save_results(results, results_file)\n",
    "\n",
    "    time_point = datetime.timedelta(seconds = time.time() - t_start_gridpoint)\n",
    "    total_time = datetime.timedelta(seconds = time.time() - t_start)\n",
    "    print(f\"{dt.now()} All links in gridpoint found. Time: {time_point}.\"\n",
    "          + f\" Total time so far: {total_time}\")\n",
    "    print(\"\")\n",
    "    \n",
    "print(f\"{dt.now()} Execution complete. Total time: {total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tigramite",
   "language": "python",
   "name": "tigramite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
