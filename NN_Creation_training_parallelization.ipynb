{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network creation\n",
    "\n",
    "This script takes results from \"aggregated results\", and generates neural\n",
    "networks based on them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, datetime\n",
    "from datetime import datetime as dt\n",
    "t_init = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from utils.setup import SetupNeuralNetworks\n",
    "\n",
    "argv  = sys.argv[1:]\n",
    "# argv  = [\"-c\", \"./nn_config/cfg_testing.yml\"]\n",
    "# argv  = [\"-c\", \"./nn_config/cfg_NN_Creation.yml\"]\n",
    "# argv  = [\"-c\", \"./nn_config/cfg_NN_Creation_rasp.yml\"]\n",
    "# argv  = [\"-c\", \"./nn_config/cfg_NN_Creation_climate_invariant.yml\"]\n",
    "# argv  = [\"-c\", \"./nn_config/cfg_NN_Creation_rasp_tphystnd_1-5.yml\"]\n",
    "# argv  = [\"-c\", \"./nn_config/cfg_NN_Creation_climate_invariant_tphystnd_26-30.yml\"]\n",
    "# argv  = [\"-c\", \"./nn_config/220224_threshold_optimization/single/cfg_NN_Creation_rasp_tphystnd_28.yml\"]\n",
    "# argv  = [\"-c\", \"./nn_config/220224_threshold_optimization/pdf/cfg_NN_Creation_rasp_parcorr_pdf-0.59_phq_24.yml\"]\n",
    "\n",
    "setup = SetupNeuralNetworks(argv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can check both, attributes and methods in **setup** by, for example:\\\n",
    "**dir(setup)\\\n",
    "setup.__dict__** # setup.__dict__.keys() & setup.__dict__.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horovod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow.keras as hvd\n",
    "\n",
    "# Horovod: initialize Horovod.\n",
    "hvd.init()\n",
    "\n",
    "# Horovod: pin GPU to be used to process local rank (one GPU per process)\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_memory_growth(gpu, True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()],'GPU')\n",
    "\n",
    "# Flag to indicate whether this is the MPI root\n",
    "# is_root = hvd.rank() == 0\n",
    "\n",
    "# # Horovod: adjust number of epochs based on number of GPUs.\n",
    "# epochs = int(math.ceil(setup.epochs / hvd.size()))\n",
    "# print('\\n')\n",
    "# print(f'hvd.size: {hvd.size()}')\n",
    "# print(f'epochs: {setup.epochs}')\n",
    "# print('\\n')\n",
    "\n",
    "# Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "# This is necessary to ensure consistent initialization of all workers when\n",
    "# training is started with random weights or restored from a checkpoint.\n",
    "setup.horovod = hvd.callbacks.BroadcastGlobalVariablesCallback(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_networks.models_parallelization import generate_models\n",
    "model_descriptions = generate_models(setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model_descriptions** is a list with all models to be trained. Note, however, that each element in model_description is a class obj. and one can check both, attributes and methods by for example:\\\n",
    "dir(dir(model_descriptions[0]))\\\n",
    "model_descriptions[0].__dict__** # model_descriptions[0].__dict__.keys() & model_descriptions[0].__dict__.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all models in the model list and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_networks.training_parallelization import train_all_models\n",
    "\n",
    "train_all_models(model_descriptions, setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = datetime.timedelta(\n",
    "    seconds=time.time() - t_init\n",
    ")\n",
    "print(f\"{dt.now()} Finished. Time: {t_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalnncam",
   "language": "python",
   "name": "conda_causalnncam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
