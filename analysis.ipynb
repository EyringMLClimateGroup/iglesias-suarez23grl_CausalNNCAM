{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Load results files and run analysis on them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tigramite import plotting as tp\n",
    "import numpy as np\n",
    "\n",
    "def plot_links(results,\n",
    "               save_name = None,\n",
    "               figsize = (16, 16)\n",
    "              ):\n",
    "    \"\"\"\n",
    "    This function is copied from the basic tutorial, but it may not be\n",
    "    generalizable: It had issues with output from pcmciplus\n",
    "    \"\"\"\n",
    "\n",
    "    link_matrix = results[\"link_matrix\"]\n",
    "    var_names = np.array(results[\"var_names\"])\n",
    "#     val_matrix = results['val_matrix']\n",
    "    \n",
    "    links = results[\"links\"]\n",
    "    linked_variables = set() # Avoids duplicates and sorts when list\n",
    "    for child, parents_list in links.items():\n",
    "        if len(parents_list) > 0:\n",
    "            linked_variables.add(child)\n",
    "            for parent in parents_list:\n",
    "                linked_variables.add(parent[0])\n",
    "    if len(linked_variables) != 0:\n",
    "        linked_variables = list(linked_variables)\n",
    "    else:\n",
    "        linked_variables = range(len(links))\n",
    "    \n",
    "    tp.plot_graph(\n",
    "        figsize = figsize,\n",
    "#         val_matrix = val_matrix[linked_variables][:,linked_variables],\n",
    "        link_matrix = link_matrix[linked_variables][:,linked_variables],\n",
    "        var_names = var_names[linked_variables],\n",
    "        link_colorbar_label = 'cross-MCI',\n",
    "        node_colorbar_label = 'auto-MCI',\n",
    "        arrow_linewidth = 5,\n",
    "        node_size = 0.15,\n",
    "        save_name = save_name,\n",
    "        show_colorbar = False\n",
    "    ); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import getopt\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import utils.utils as utils\n",
    "from utils.constants import SPCAM_Vars, DATA_FOLDER, ANCIL_FILE\n",
    "# from utils.constants import PLOT_FILE_PATTERN\n",
    "from utils.constants import experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argv           = sys.argv[1:]\n",
    "# argv           = ['-c', 'cfg_pipeline.yml']\n",
    "# argv           = ['-c', 'cfg_lon120.yml']\n",
    "try:\n",
    "    opts, args = getopt.getopt(argv,\"hc:a\",[\"cfg_file=\",\"add=\"])\n",
    "except getopt.GetoptError:\n",
    "    print ('pipeline.py -c [cfg_file] -a [add]')\n",
    "    sys.exit(2)\n",
    "for opt, arg in opts:\n",
    "    if opt == '-h':\n",
    "        print ('pipeline.py -c [cfg_file]')\n",
    "        sys.exit()\n",
    "    elif opt in (\"-c\", \"--cfg_file\"):\n",
    "        yml_cfgFilenm = arg\n",
    "    elif opt in (\"-a\", \"--add\"):\n",
    "        pass\n",
    "\n",
    "# YAML config file\n",
    "yml_cfgFile       = open(yml_cfgFilenm)\n",
    "yml_cfg           = yaml.load(yml_cfgFile, Loader=yaml.FullLoader)\n",
    "\n",
    "# Load specifications\n",
    "# analysis = yml_cfg['analysis']\n",
    "analysis = \"single\" # Only single is supported right now\n",
    "spcam_parents     = yml_cfg['spcam_parents']\n",
    "spcam_children    = yml_cfg['spcam_children']\n",
    "pc_alphas         = yml_cfg['pc_alphas']\n",
    "region            = yml_cfg['region']\n",
    "lim_levels        = yml_cfg['lim_levels']\n",
    "target_levels     = yml_cfg['target_levels']\n",
    "verbosity         = yml_cfg['verbosity']\n",
    "output_folder     = yml_cfg['output_folder']\n",
    "plots_folder = yml_cfg['plots_folder']\n",
    "output_file_pattern = yml_cfg['output_file_pattern'][analysis]\n",
    "plot_file_pattern = yml_cfg['plot_file_pattern']\n",
    "overwrite         = False\n",
    "\n",
    "Path(plots_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Region / Gridpoints\n",
    "if region is False:\n",
    "    region     = [ [-90,90] , [0,-.5] ] # All\n",
    "gridpoints = utils.get_gridpoints(region)\n",
    "\n",
    "## Children levels (parents includes all)\n",
    "if lim_levels is not False and target_levels is False:\n",
    "    target_levels = utils.get_levels(lim_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model's grid\n",
    "levels, latitudes, longitudes = utils.read_ancilaries(Path(DATA_FOLDER, ANCIL_FILE))\n",
    "\n",
    "## Latitude / Longitude indexes\n",
    "idx_lats = [utils.find_closest_value(latitudes, gridpoint[0])      for gridpoint in gridpoints]\n",
    "idx_lons = [utils.find_closest_longitude(longitudes, gridpoint[1]) for gridpoint in gridpoints]\n",
    "\n",
    "## Level indexes (children & parents)\n",
    "parents_idx_levs = [[round(lev, 2), i] for i, lev in enumerate(levels)] # All\n",
    "if target_levels is not False:\n",
    "    children_idx_levs = [[lev, utils.find_closest_value(levels, lev)] for lev in target_levels]\n",
    "else:\n",
    "    children_idx_levs = parents_idx_levs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables\n",
    "spcam_vars_include = spcam_parents + spcam_children\n",
    "var_list = [var for var in SPCAM_Vars if var.label in spcam_vars_include]\n",
    "var_parents = [var for var in var_list if var.type == \"in\"]\n",
    "var_children = [var for var in var_list if var.type == \"out\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parents_from_links(links):\n",
    "    linked_variables = set() # Avoids duplicates and sorts when list\n",
    "    for parents_list in links.values():\n",
    "        if len(parents_list) > 0:\n",
    "            linked_variables.add(child)\n",
    "            for parent in parents_list:\n",
    "                linked_variables.add(parent[0])\n",
    "    return [(i in linked_variables)  for i in range(len(links))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "KEY_PATTERN = \"{var_name}-{level}\"\n",
    "\n",
    "aggregated_results = dict()\n",
    "for child in var_children:\n",
    "    print(f\"Variable: {child.name}\")\n",
    "    for i_grid, (lat, lon) in enumerate(gridpoints):\n",
    "\n",
    "        if child.dimensions == 2:\n",
    "            child_levels = [[levels[-1],0]]\n",
    "            key = child.name\n",
    "        elif child.dimensions == 3:\n",
    "            child_levels = children_idx_levs\n",
    "        for level in child_levels:\n",
    "            if child.dimensions == 3:\n",
    "                key = KEY_PATTERN.format(\n",
    "                        var_name = child.name,\n",
    "                        level = round(level[0], 2)\n",
    "                )\n",
    "            aggregated_pc_alpha = aggregated_results.get(key, dict())\n",
    "            results_file = utils.generate_results_filename(\n",
    "                    child, level[1], lat, lon, experiment, output_file_pattern, output_folder)\n",
    "            if not results_file.is_file():\n",
    "                print(f\"File {results_file} not found, skipping.\")\n",
    "                continue\n",
    "            results = utils.load_results(results_file)\n",
    "            for pc_alpha, alpha_result in results.items():\n",
    "                if len(alpha_result) > 0:\n",
    "                    links = alpha_result[\"links\"]\n",
    "                    parents = get_parents_from_links(links)\n",
    "                    aggregated = aggregated_pc_alpha.get(pc_alpha, list())\n",
    "                    aggregated.append(parents)\n",
    "                    aggregated_pc_alpha[pc_alpha] = aggregated\n",
    "                    var_names = alpha_result[\"var_names\"] # TODO Very uncomfortable way to obtain this data. Should be metadata\n",
    "            aggregated_results[key] = aggregated_pc_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [.5, .6, .7, .8, .9, 1]\n",
    "var_names = np.array(var_names)\n",
    "\n",
    "for child, result in aggregated_results.items():\n",
    "    print(child)\n",
    "    for pc_alpha, parents_matrix in result.items():\n",
    "        parents_matrix = np.array(parents_matrix)\n",
    "        parents_percent = parents_matrix.sum(axis = 0) / parents_matrix.shape[0]\n",
    "        print(pc_alpha)\n",
    "        for threshold in thresholds:\n",
    "            parents_filtered = parents_percent >= threshold\n",
    "            parents = [i for i in range(len(parents_filtered)) if parents_filtered[i]]\n",
    "#             print(parents_filtered)\n",
    "#             print(parents)\n",
    "            print(f\"Threshold {threshold}:\\t{var_names[parents]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "len_grid = len(gridpoints)\n",
    "t_start = time.time()\n",
    "for i_grid, (lat, lon) in enumerate(gridpoints):\n",
    "    idx_lat = idx_lats[i_grid]\n",
    "    idx_lon = idx_lons[i_grid]\n",
    "    \n",
    "    t_start_gridpoint = time.time()\n",
    "    print(f\"Gridpoint {i_grid+1}/{len_grid}:\"\n",
    "          + f\"lat={lat} ({idx_lat}), lon={lon} ({idx_lon})\")\n",
    "    for child in var_children:\n",
    "        print(f\"Variable: {child.name}\")\n",
    "        if child.dimensions == 2:\n",
    "            child_levels = [[levels[-1],0]]\n",
    "        elif child.dimensions == 3:\n",
    "            child_levels = children_idx_levs\n",
    "        for level in child_levels:\n",
    "            results = utils.load_results(child, level[1], lat, lon, experiment,\n",
    "                                         output_file_pattern, output_folder)\n",
    "\n",
    "            print(f\"Plotting links for {child.name} at level {level[1]+1}\")\n",
    "            t_before_plot_linkgs = time.time()\n",
    "            # Plotting\n",
    "            for pc_alpha, alpha_result in results.items():\n",
    "                print(f\"pc_alpha = {pc_alpha}\")\n",
    "                plot_file = Path(plots_folder, plot_file_pattern.format(\n",
    "                        var_name = child.name,\n",
    "                        level = level[1]+1,\n",
    "                        lat = int(lat),\n",
    "                        lon = int(lon),\n",
    "                        pc_alpha = pc_alpha,\n",
    "                        experiment = experiment\n",
    "                ))\n",
    "                if not overwrite and plot_file.is_file():\n",
    "                    print(f\"Found file {plot_file}, skipping.\")\n",
    "                    continue # Ignore this result\n",
    "                if len(alpha_result) > 0:\n",
    "                    print(f\"Plotting to {plot_file}\")\n",
    "                    plot_links(alpha_result, save_name = plot_file)\n",
    "                else:\n",
    "                    print(\"Results are empty, skipping.\")\n",
    "            time_plot_links = datetime.timedelta(\n",
    "                    seconds = time.time() - t_before_plot_linkgs\n",
    "            )\n",
    "            print(f\"Plotted. Time: {time_plot_links}\")\n",
    "\n",
    "    time_point = datetime.timedelta(\n",
    "            seconds = time.time() - t_start_gridpoint)\n",
    "    print(f\"All links in gridpoint plotted. Time: {time_point}\")\n",
    "total_time = datetime.timedelta(seconds = time.time() - t_start)\n",
    "print(f\"Execution complete. Total time: {total_time}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tigramite",
   "language": "python",
   "name": "tigramite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
