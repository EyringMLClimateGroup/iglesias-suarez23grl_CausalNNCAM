{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Load results files and run analysis on them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tigramite import plotting as tp\n",
    "import numpy as np\n",
    "\n",
    "def plot_links(results,\n",
    "               save_name = None,\n",
    "               figsize = (16, 16),\n",
    "               node_size = 0.15\n",
    "              ):\n",
    "    \"\"\"\n",
    "    This function is copied from the basic tutorial, but it may not be\n",
    "    generalizable: It had issues with output from pcmciplus\n",
    "    \"\"\"\n",
    "\n",
    "    link_matrix = results[\"link_matrix\"]\n",
    "    var_names = np.array(results[\"var_names\"])\n",
    "#     val_matrix = results['val_matrix']\n",
    "    \n",
    "    links = results[\"links\"]\n",
    "    linked_variables = set() # Avoids duplicates and sorts when list\n",
    "    for child, parents_list in links.items():\n",
    "        if len(parents_list) > 0:\n",
    "            linked_variables.add(child)\n",
    "            for parent in parents_list:\n",
    "                linked_variables.add(parent[0])\n",
    "    if len(linked_variables) != 0:\n",
    "        linked_variables = list(linked_variables)\n",
    "        # Raise an exception if there is a different number of links\n",
    "        # on the reduced link_matrix\n",
    "        assert((link_matrix == True).sum()\n",
    "               == (link_matrix[linked_variables][:,linked_variables] == True).sum())\n",
    "    else:\n",
    "        linked_variables = range(len(links))\n",
    "    \n",
    "    tp.plot_graph(\n",
    "        figsize = figsize,\n",
    "#         val_matrix = val_matrix[linked_variables][:,linked_variables],\n",
    "        link_matrix = link_matrix[linked_variables][:,linked_variables],\n",
    "        var_names = var_names[linked_variables],\n",
    "        link_colorbar_label = 'cross-MCI',\n",
    "        node_colorbar_label = 'auto-MCI',\n",
    "        arrow_linewidth = 5,\n",
    "        node_size = node_size,\n",
    "        save_name = save_name,\n",
    "        show_colorbar = False\n",
    "    ); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import utils.utils as utils\n",
    "\n",
    "from utils.setup import Setup\n",
    "\n",
    "argv           = sys.argv[1:]\n",
    "# argv           = ['-c', 'cfg_pipeline.yml']\n",
    "# argv           = ['-c', 'cfg_concat_lon120.yml']\n",
    "# argv           = ['-c', 'cfg_single_lon120.yml']\n",
    "\n",
    "setup = Setup(argv)\n",
    "\n",
    "Path(setup.plots_folder).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parents_from_links(links):\n",
    "    linked_variables = set() # Avoids duplicates and sorts when list\n",
    "    for parents_list in links.values():\n",
    "        if len(parents_list) > 0:\n",
    "            linked_variables.add(child)\n",
    "            for parent in parents_list:\n",
    "                linked_variables.add(parent[0])\n",
    "    return [(i in linked_variables)  for i in range(len(links))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results_single(key, aggregated_results, setup, errors):\n",
    "    for i_grid, (lat, lon) in enumerate(setup.gridpoints):\n",
    "        aggregated_pc_alpha = aggregated_results.get(key, dict())\n",
    "        results_file = utils.generate_results_filename_single(\n",
    "                child, level[1], lat, lon, setup.experiment,\n",
    "                setup.output_file_pattern, setup.output_folder)\n",
    "        if not results_file.is_file():\n",
    "#             print(f\"Results file {results_file} not found, skipping.\")\n",
    "            not_found_list = errors.get(\"not_found\", list())\n",
    "            if results_file not in not_found_list:\n",
    "                not_found_list.append(results_file)\n",
    "                errors[\"not_found\"] = not_found_list\n",
    "            continue\n",
    "        results = utils.load_results(results_file)\n",
    "        for pc_alpha, alpha_result in results.items():\n",
    "            if len(alpha_result) > 0:\n",
    "                links = alpha_result[\"links\"]\n",
    "                parents = get_parents_from_links(links)\n",
    "                aggregated = aggregated_pc_alpha.get(pc_alpha, list())\n",
    "                aggregated.append(parents)\n",
    "                aggregated_pc_alpha[pc_alpha] = aggregated\n",
    "                global var_names\n",
    "                var_names = alpha_result[\"var_names\"] # TODO Very uncomfortable way to obtain this data. Should be metadata\n",
    "            else:\n",
    "#                 print(f\"File {results_file} is empty, skipping.\") # Prints too often\n",
    "                is_empty_list = errors.get(\"is_empty\", list())\n",
    "                if results_file not in is_empty_list:\n",
    "                    is_empty_list.append(results_file)\n",
    "                    errors[\"is_empty\"] = is_empty_list\n",
    "        aggregated_results[key] = aggregated_pc_alpha\n",
    "    # Doesn't return, instead modifies the received `aggregated results` object\n",
    "\n",
    "    \n",
    "def aggregate_results_concat(key, aggregated_results, setup, errors):\n",
    "    aggregated_pc_alpha = aggregated_results.get(key, dict())\n",
    "    results_file = utils.generate_results_filename_concat(\n",
    "            child, level[-1], setup.gridpoints, setup.experiment,\n",
    "            setup.output_file_pattern, setup.output_folder)\n",
    "    if not results_file.is_file():\n",
    "#         print(f\"Results file {results_file} not found, skipping.\")\n",
    "        not_found_list = errors.get(\"not_found\", list())\n",
    "        if results_file not in not_found_list:\n",
    "            not_found_list.append(results_file)\n",
    "            errors[\"not_found\"] = not_found_list\n",
    "        return\n",
    "    results = utils.load_results(results_file)\n",
    "    for pc_alpha, alpha_result in results.items():\n",
    "        if len(alpha_result) > 0:\n",
    "            links = alpha_result[\"links\"]\n",
    "            parents = get_parents_from_links(links)\n",
    "            aggregated = aggregated_pc_alpha.get(pc_alpha, list())\n",
    "            aggregated.append(parents)\n",
    "            aggregated_pc_alpha[pc_alpha] = aggregated\n",
    "            global var_names\n",
    "            var_names = alpha_result[\"var_names\"] # TODO Very uncomfortable way to obtain this data. Should be metadata\n",
    "        else:\n",
    "#             print(f\"File {results_file} is empty, skipping.\") # Prints too often\n",
    "            is_empty_list = errors.get(\"is_empty\", list())\n",
    "            if results_file not in is_empty_list:\n",
    "                is_empty_list.append(results_file)\n",
    "                errors[\"is_empty\"] = is_empty_list\n",
    "    aggregated_results[key] = aggregated_pc_alpha\n",
    "    # Doesn't return, instead modifies the received `aggregated results` object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_variables(var_children, levels):\n",
    "    total = 0\n",
    "    for child in var_children:\n",
    "        if child.dimensions == 2:\n",
    "            total += 1\n",
    "        elif child.dimensions == 3:\n",
    "            total += len(levels)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "KEY_PATTERN = \"{var_name}-{level}\"\n",
    "\n",
    "aggregated_results = dict()\n",
    "errors = dict()\n",
    "\n",
    "total_vars = count_total_variables(\n",
    "    setup.var_children, setup.children_idx_levs)\n",
    "total_files = total_vars * len(setup.gridpoints)\n",
    "file_progress = 0\n",
    "step_progress = 1\n",
    "step = 5\n",
    "\n",
    "for child in setup.var_children:\n",
    "    print(f\"Variable: {child.name}\")\n",
    "    \n",
    "    if child.dimensions == 2:\n",
    "        child_levels = [[setup.levels[-1],0]]\n",
    "        key = child.name\n",
    "    elif child.dimensions == 3:\n",
    "        child_levels = setup.children_idx_levs\n",
    "    for level in child_levels:      \n",
    "        if child.dimensions == 3:\n",
    "            key = KEY_PATTERN.format(\n",
    "                    var_name = child.name,\n",
    "                    level = round(level[0], 2)\n",
    "            )\n",
    "        if setup.analysis == \"single\":\n",
    "            aggregate_results_single(\n",
    "                key, aggregated_results, setup, errors)\n",
    "        elif setup.analysis == \"concat\":\n",
    "            aggregate_results_concat(\n",
    "                key, aggregated_results, setup, errors)\n",
    "        \n",
    "        file_progress += len(setup.gridpoints)\n",
    "        if(file_progress == total_files or\n",
    "           ((file_progress / total_files * 100) >= step * step_progress)):\n",
    "            step_progress += 1\n",
    "            print(\"Progress: {:.2f}% - {} of {} files\".format(\n",
    "                    file_progress / total_files * 100,\n",
    "                    file_progress,\n",
    "                    total_files\n",
    "                ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print errors found loading aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ERRORS\\n======\")\n",
    "for error_type, error_list in errors.items():\n",
    "    msg = \"{}: {} of {} files ({:.2f}%)\".format(\n",
    "            error_type,\n",
    "            len(error_list),\n",
    "            total_files,\n",
    "            len(error_list)/total_files*100\n",
    "    )\n",
    "    print(msg)\n",
    "    print(\"-\" * len(msg))\n",
    "    for file in error_list:\n",
    "        print(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# thresholds = [.2, .3, .5, .6]\n",
    "thresholds = [.3, .5]\n",
    "# thresholds = [1]\n",
    "pc_alphas_filter = [str(a) for a in [.001, .01, .1]]\n",
    "var_names_np = np.array(var_names)\n",
    "\n",
    "# Print analysis\n",
    "dict_child_parents = dict()\n",
    "for child, result in aggregated_results.items():\n",
    "    print(f\"\\n{child}\")\n",
    "    dict_pc_alpha_parents = dict()\n",
    "    for pc_alpha, parents_matrix in result.items():\n",
    "        dict_threshold_parents = dict()\n",
    "        if pc_alpha not in pc_alphas_filter:\n",
    "            continue # Skip this pc alpha\n",
    "        parents_matrix = np.array(parents_matrix)\n",
    "        parents_percent = parents_matrix.sum(axis = 0) / parents_matrix.shape[0]\n",
    "#         dict_pc_alpha_parents[\"percent\"] = parents_percent\n",
    "        print(f\"pc_alpha = {pc_alpha}\")\n",
    "        for threshold in thresholds:\n",
    "            parents_filtered = parents_percent >= threshold\n",
    "            parents = [i for i in range(len(parents_filtered)) if parents_filtered[i]]\n",
    "#             print(parents_filtered)\n",
    "#             print(parents)\n",
    "            dict_threshold_parents[str(threshold)] = parents\n",
    "            print(f\"* Threshold {threshold}:\\t{var_names_np[parents]}\")\n",
    "        dict_pc_alpha_parents[pc_alpha] = dict_threshold_parents\n",
    "    dict_child_parents[child] = dict_pc_alpha_parents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for each pc_alpha and threshold combination with all children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate results file for filter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names_parents = var_names[:-1] # NOTE: This assumes that the list has only one child\n",
    "var_names_children = list()\n",
    "\n",
    "dict_combinations = dict()\n",
    "len_parents = len(var_names_parents)\n",
    "len_total = len_parents + len(dict_child_parents)\n",
    "for i_child, (child, dict_pc_alpha_parents) in enumerate(dict_child_parents.items()):\n",
    "    i_child = i_child + len_parents\n",
    "    var_names_children.append(child)\n",
    "    for pc_alpha, dict_threshold_parents in dict_pc_alpha_parents.items():\n",
    "        for threshold, parents in dict_threshold_parents.items():\n",
    "            key = f\"a{pc_alpha}-t{threshold}\"\n",
    "            combination_results = dict_combinations.get(key, dict())\n",
    "            \n",
    "            # Build links\n",
    "            links = combination_results.get(\n",
    "                    \"links\", {i : [] for i in range(len(var_names_parents))})\n",
    "#             links[i_child] = [(parent, -1) for parent in parents]\n",
    "            links[i_child] = [(parent, 0) for parent in parents]\n",
    "            combination_results[\"links\"] = links\n",
    "            \n",
    "            # Build link_matrix\n",
    "            link_matrix = combination_results.get(\n",
    "                    \"link_matrix\",\n",
    "#                     [[[False, False] for i in range(len_total)]\n",
    "                    [[[False] for i in range(len_total)]\n",
    "                         for j in range(len_total)])\n",
    "            for parent in parents:\n",
    "#                 link_matrix[parent][i_child] = [False, True]\n",
    "                link_matrix[parent][i_child] = [True]\n",
    "            combination_results[\"link_matrix\"] = link_matrix\n",
    "            \n",
    "            # Store results\n",
    "            dict_combinations[key] = combination_results\n",
    "\n",
    "all_var_names = var_names_parents + var_names_children # Concatenation\n",
    "for combination, combination_results in dict_combinations.items():\n",
    "    combination_results[\"link_matrix\"] = np.array(combination_results[\"link_matrix\"])\n",
    "    combination_results[\"var_names\"] = all_var_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combination, combination_results in dict_combinations.items():\n",
    "    print(combination)\n",
    "    plot_filename = \"{cfg}_{combination}.png\".format(\n",
    "            cfg = setup.yml_filename.rsplit(\".\")[0],\n",
    "            combination = combination\n",
    "    )\n",
    "    plot_file = Path(setup.plots_folder, plot_filename)\n",
    "    if not setup.overwrite and plot_file.is_file():\n",
    "        print(f\"Found file {plot_file}, skipping.\")\n",
    "        continue # Ignore this result\n",
    "    plot_links(\n",
    "        combination_results,\n",
    "        save_name = plot_file,\n",
    "        figsize = (48, 48),\n",
    "        node_size = 0.05\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot every pc alpha of a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "len_grid = len(setup.gridpoints)\n",
    "t_start = time.time()\n",
    "for i_grid, (lat, lon) in enumerate(setup.gridpoints):\n",
    "    if setup.analysis == \"concat\":\n",
    "        print(\"Analysis of concatenated files is currently unsupported, skipping.\")\n",
    "        break\n",
    "    idx_lat = setup.idx_lats[i_grid]\n",
    "    idx_lon = setup.idx_lons[i_grid]\n",
    "    \n",
    "    t_start_gridpoint = time.time()\n",
    "    print(f\"Gridpoint {i_grid+1}/{len_grid}:\"\n",
    "          + f\"lat={lat} ({idx_lat}), lon={lon} ({idx_lon})\")\n",
    "    for child in setup.var_children:\n",
    "        print(f\"Variable: {child.name}\")\n",
    "        if child.dimensions == 2:\n",
    "            child_levels = [[setup.levels[-1],0]]\n",
    "        elif child.dimensions == 3:\n",
    "            child_levels = setup.children_idx_levs\n",
    "        for level in child_levels:\n",
    "            results_file = utils.generate_results_filename_single(\n",
    "                    child, level[1], lat, lon, setup.experiment,\n",
    "                    setup.output_file_pattern, setup.output_folder)\n",
    "            if not results_file.is_file():\n",
    "                print(f\"Results file {results_file} not found, skipping.\")\n",
    "                continue\n",
    "            results = utils.load_results(results_file)\n",
    "\n",
    "            print(f\"Plotting links for {child.name} at level {level[1]+1}\")\n",
    "            t_before_plot_linkgs = time.time()\n",
    "            # Plotting\n",
    "            for pc_alpha, alpha_result in results.items():\n",
    "                print(f\"pc_alpha = {pc_alpha}\")\n",
    "                plot_file = Path(\n",
    "                        setup.plots_folder,\n",
    "                        setup.plot_file_pattern.format(\n",
    "                            var_name = child.name,\n",
    "                            level = level[1]+1,\n",
    "                            lat = int(lat),\n",
    "                            lon = int(lon),\n",
    "                            pc_alpha = pc_alpha,\n",
    "                            experiment = setup.experiment\n",
    "                        )\n",
    "                )\n",
    "                if not setup.overwrite and plot_file.is_file():\n",
    "                    print(f\"Found file {plot_file}, skipping.\")\n",
    "                    continue # Ignore this result\n",
    "                if len(alpha_result) > 0:\n",
    "                    print(f\"Plotting to {plot_file}\")\n",
    "                    plot_links(alpha_result, save_name = plot_file)\n",
    "                else:\n",
    "                    print(\"Results are empty, skipping.\")\n",
    "            time_plot_links = datetime.timedelta(\n",
    "                    seconds = time.time() - t_before_plot_linkgs\n",
    "            )\n",
    "            print(f\"Plotted. Time: {time_plot_links}\")\n",
    "\n",
    "    time_point = datetime.timedelta(\n",
    "            seconds = time.time() - t_start_gridpoint)\n",
    "    print(f\"All links in gridpoint plotted. Time: {time_point}\")\n",
    "total_time = datetime.timedelta(seconds = time.time() - t_start)\n",
    "print(f\"Execution complete. Total time: {total_time}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tigramite",
   "language": "python",
   "name": "tigramite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
